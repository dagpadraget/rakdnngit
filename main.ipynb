{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagpadraget/rakdnngit/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYZM02_5DP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edaea1be-b2f9-4186-e250-468cdbe441f1"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wte7rgxF9Unh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b0df4ca3-b449-49ab-9f47-d577774b7d1d"
      },
      "source": [
        "!rm -fr rakdnngit\n",
        "!rm -fr tmp\n",
        "!git clone https://github.com/dagpadraget/rakdnngit"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rakdnngit'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 116 (delta 57), reused 85 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (116/116), 13.27 MiB | 7.30 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jo-CRRw5uL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe207627-4bc9-4ce5-8549-d84274e6f63c"
      },
      "source": [
        "cd rakdnngit"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rakdnngit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ammp135sPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "1caa1ef7-f509-442d-99ca-fed95d6e14bc"
      },
      "source": [
        "!pip3 install -r requirement.txt"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 1)) (1.17.4)\n",
            "Requirement already satisfied: Keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 2)) (2.3.1)\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 3)) (1.0.8)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: tensorboard==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: tensorflow-tensorboard==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r requirement.txt (line 8)) (0.1.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.3.1->-r requirement.txt (line 2)) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.3.1->-r requirement.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.3.1->-r requirement.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras==2.3.1->-r requirement.txt (line 2)) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (0.33.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r requirement.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->-r requirement.txt (line 6)) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->-r requirement.txt (line 6)) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->-r requirement.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->-r requirement.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->-r requirement.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0->-r requirement.txt (line 6)) (0.1.8)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==0.1.8->-r requirement.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==0.1.8->-r requirement.txt (line 8)) (0.9999999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zeX34Xs497T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnbToJSc4OZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a80b914-1ad2-4633-f5ad-4d866a34c3d9"
      },
      "source": [
        "cd tmp"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rakdnngit/tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEhKd_6h97dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir rakdnngit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymv7oJAa-D6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df1205fd-df5d-43fc-875e-a6f0f97bef3b"
      },
      "source": [
        "cd /content/rakdnngit"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rakdnngit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgX2P3508nIL",
        "colab_type": "code",
        "outputId": "245c93b5-c286-4065-9d42-2a874bb4626d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 main.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "number of sequences= 27335 \n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-01-06 13:48:30.577182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-01-06 13:48:30.612145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.612837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-06 13:48:30.613165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-06 13:48:30.615036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-06 13:48:30.616957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-06 13:48:30.617308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-06 13:48:30.618957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-06 13:48:30.619749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-06 13:48:30.622988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-06 13:48:30.623104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.623776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.624339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-06 13:48:30.629477: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-01-06 13:48:30.631866: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28d8bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-06 13:48:30.631900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-01-06 13:48:30.739784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.740597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28d8d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-01-06 13:48:30.740629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-01-06 13:48:30.740830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.741342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-01-06 13:48:30.741391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-06 13:48:30.741408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-01-06 13:48:30.741421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-01-06 13:48:30.741435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-01-06 13:48:30.741447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-01-06 13:48:30.741459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-01-06 13:48:30.741472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-01-06 13:48:30.741564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.742138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.742667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-01-06 13:48:30.742756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-01-06 13:48:30.743781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-01-06 13:48:30.743808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-01-06 13:48:30.743818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-01-06 13:48:30.743908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.744443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-01-06 13:48:30.744977: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-01-06 13:48:30.745016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/500\n",
            "2020-01-06 13:48:32.019236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "27335/27335 [==============================] - 10s 351us/step - loss: 6.5120\n",
            "Epoch 2/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 6.1888\n",
            "Epoch 3/500\n",
            "27335/27335 [==============================] - 8s 309us/step - loss: 6.0035\n",
            "Epoch 4/500\n",
            "27335/27335 [==============================] - 9s 313us/step - loss: 5.8820\n",
            "Epoch 5/500\n",
            "27335/27335 [==============================] - 8s 307us/step - loss: 5.7775\n",
            "Epoch 6/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.6789\n",
            "Epoch 7/500\n",
            "27335/27335 [==============================] - 8s 311us/step - loss: 5.5793\n",
            "Epoch 8/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.4771\n",
            "Epoch 9/500\n",
            "27335/27335 [==============================] - 9s 312us/step - loss: 5.3815\n",
            "Epoch 10/500\n",
            "27335/27335 [==============================] - 9s 315us/step - loss: 5.2874\n",
            "Epoch 11/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.1966\n",
            "Epoch 12/500\n",
            "27335/27335 [==============================] - 9s 311us/step - loss: 5.1171\n",
            "Epoch 13/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.0781\n",
            "Epoch 14/500\n",
            "27335/27335 [==============================] - 9s 312us/step - loss: 5.0494\n",
            "Epoch 15/500\n",
            "27335/27335 [==============================] - 8s 311us/step - loss: 5.0201\n",
            "Epoch 16/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.0127\n",
            "Epoch 17/500\n",
            "27335/27335 [==============================] - 9s 313us/step - loss: 5.0755\n",
            "Epoch 18/500\n",
            "27335/27335 [==============================] - 9s 312us/step - loss: 5.1037\n",
            "Epoch 19/500\n",
            "27335/27335 [==============================] - 9s 315us/step - loss: 5.1182\n",
            "Epoch 20/500\n",
            "27335/27335 [==============================] - 9s 315us/step - loss: 5.2239\n",
            "Epoch 21/500\n",
            "27335/27335 [==============================] - 9s 313us/step - loss: 5.3251\n",
            "Epoch 22/500\n",
            "27335/27335 [==============================] - 9s 311us/step - loss: 5.4231\n",
            "Epoch 23/500\n",
            "27335/27335 [==============================] - 9s 311us/step - loss: 5.4310\n",
            "Epoch 24/500\n",
            "27335/27335 [==============================] - 9s 311us/step - loss: 5.3744\n",
            "Epoch 25/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.4145\n",
            "Epoch 26/500\n",
            "27335/27335 [==============================] - 8s 310us/step - loss: 5.5015\n",
            "Epoch 27/500\n",
            "27335/27335 [==============================] - 8s 309us/step - loss: 5.4136\n",
            "Epoch 28/500\n",
            "27335/27335 [==============================] - 8s 309us/step - loss: 5.4060\n",
            "Epoch 29/500\n",
            "27335/27335 [==============================] - 9s 312us/step - loss: 5.4226\n",
            "Epoch 30/500\n",
            "27335/27335 [==============================] - 8s 311us/step - loss: 5.3932\n",
            "Epoch 31/500\n",
            "27335/27335 [==============================] - 8s 308us/step - loss: 5.3528\n",
            "Epoch 32/500\n",
            "27335/27335 [==============================] - 9s 312us/step - loss: 5.3459\n",
            "Epoch 33/500\n",
            "27335/27335 [==============================] - 8s 308us/step - loss: 5.3398\n",
            "Epoch 34/500\n",
            "21600/27335 [======================>.......] - ETA: 1s - loss: 5.2861"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztsafPFT9_ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGCiYM9-Brw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "more localdata/hbshort.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THsPNQzRZlpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls -rla /content/tmp/rakdnngit/jobdir/rak_dnngit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTfn8YtE7t9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *********************************************************************************************************************\n",
        "# Library imports\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input, Conv2D,LeakyReLU, Flatten, Dense,Reshape,Activation,Conv2DTranspose,Embedding,Dropout,LSTM\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils import np_utils\n",
        "import re\n",
        "import argparse\n",
        "# *********************************************************************************************************************\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8K1XHpg2Xxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext_seq_length=5\n",
        "storyfile=\"hblang.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvpS4dDx7wgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *********************************************************************************************************************\n",
        "# Load data from file\n",
        "def load_data(datapath):\n",
        "    filename=datapath+\"/\"+storyfile\n",
        "    print(\"story: \"+filename)\n",
        "    with open(filename,encoding=\"utf-8-sig\") as f:\n",
        "        text =f.read()\n",
        "\n",
        "    seq_length=ext_seq_length # sequence around sentence\n",
        "    step=1 # prediction step forward\n",
        "\n",
        "    start_story='| '*seq_length\n",
        "\n",
        "    text=text.lower()\n",
        "    text=start_story+text\n",
        "    text=text.replace('\\n\\n\\n\\n\\n',start_story)\n",
        "    text=text.replace('\\n',' ')\n",
        "    #text=re.sub(' +','. ',text).strip()\n",
        "    text=text.replace('..','.')\n",
        "    text=re.sub('([!\"#$%&()*+,-./:;<=>?@[\\]^_{|}~])',r' \\1 ',text)\n",
        "    text=re.sub('\\s{2,}',' ',text)\n",
        "\n",
        "    tokenizer=Tokenizer(char_level=False,filters='')\n",
        "    tokenizer.fit_on_texts([text])\n",
        "    total_words=len(tokenizer.word_index)+1\n",
        "    token_list=tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    return token_list, seq_length,step,total_words,start_story,tokenizer\n",
        "# *********************************************************************************************************************"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DtiDvkn5JMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text2(seed_text,next_words,model,max_sequence_len,temp,start_story,tokenizer):\n",
        "    token_list = np.array(tokenizer.texts_to_sequences([seed_text])[0])\n",
        "    token_list=token_list[-ext_seq_length:]\n",
        "    probs = model.predict(token_list.reshape(1,len(token_list)), verbose=0)[0]\n",
        "    y_class = sample_with_temp(probs, temperature=temp)\n",
        "    output_word = tokenizer.index_word[y_class] if y_class > 0 else ''\n",
        "    return seed_text+\"=>\"+output_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zr_pQdy73fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text22(seed_text,next_words,model,max_sequence_len,temp,start_story,tokenizer):\n",
        "    token_list = np.array(tokenizer.texts_to_sequences([seed_text])[0])\n",
        "    token_list=token_list[-ext_seq_length:]\n",
        "    probs = model.predict(token_list.reshape(1,len(token_list)), verbose=0)[0]\n",
        "    \n",
        "    print(1)\n",
        "    p0=-np.sort(-probs)\n",
        "    print(2)\n",
        "    i0=np.argsort(-probs)\n",
        "    print(3)\n",
        "    print(\"words probability\",p0[0:9])\n",
        "    print(\"words index=\",i0[0:9])\n",
        "    print(4)\n",
        "    pos=0\n",
        "    for k in i0:\n",
        "      print(\"words in order=\",k,\" : \",tokenizer.index_word[k],'p=',p0[pos])\n",
        "      if pos>10:\n",
        "        break\n",
        "      pos+=1\n",
        "    print(5)\n",
        "    \n",
        "    y_class = sample_with_temp(probs, temperature=temp)\n",
        "    output_word = tokenizer.index_word[y_class] if y_class > 0 else ''\n",
        "    return output_word\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ6gzbtc-KWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *********************************************************************************************************************\n",
        "def sample_with_temp(preds,temperature=1.0):\n",
        "    preds=np.asarray(preds).astype('float64')\n",
        "    preds=np.log(preds)/temperature\n",
        "    exp_preds=np.exp(preds)\n",
        "    preds=exp_preds/np.sum(exp_preds)\n",
        "    probs=np.random.multinomial(1,preds,1)\n",
        "    return np.argmax(probs)\n",
        "# *********************************************************************************************************************\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7LcTptZ8Wtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmpdirname='/content/tmp/rakdnngit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIakwqKl8gO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xbatch_size=32\n",
        "xlearning_rate=0.01\n",
        "xnum_epochs=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X30AGaNS8QKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Argar:\n",
        "    pcsim = True\n",
        "    pcsimdir = tmpdirname\n",
        "    batch_size=xbatch_size\n",
        "    learning_rate=xlearning_rate\n",
        "    num_epochs=xnum_epochs\n",
        "    job_dir=tmpdirname+\"/jobdir\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gFozJvO8mG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args=Argar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVE1YLNC8n90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileandpath = os.path.join(args.job_dir, 'rak_dnngit')+\"/allincluded.model\"\n",
        "\n",
        "try:\n",
        "  model=load_model(fileandpath)\n",
        "  #model.summary()      \n",
        "  token_list, seq_length, step, total_words,start_story,tokenizer = load_data(\"/content/rakdnngit/localdata\")\n",
        "except:\n",
        "  print(\"could not find \"+fileandpath)\n",
        "  \n",
        "print(\"output from loaded model : *************************\")\n",
        "print(generate_text2(\"till handelsman och ha\", 1, model, 10, 0.01, start_story,tokenizer))\n",
        "print(generate_text2(\"gråsalva åt grisen och\", 1, model, 10, 0.01, start_story, tokenizer))\n",
        "print(generate_text2(\"hade de hamnat på\", 1, model, 10, 0.01, start_story, tokenizer))\n",
        "print(generate_text2(\"därför skrek han att\", 1, model, 10, 0.01, start_story, tokenizer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4iIu1x_iXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(generate_text22(\"sett en råseglare förr och därför skrek han att de\", 1, model, 10, 0.01, start_story,tokenizer))\n",
        "print(generate_text22(\"sett en hamster och därför så skrek han att de\", 1, model, 10, 0.01, start_story,tokenizer))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}